{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev: Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent)) \n",
    "\n",
    "\n",
    "from radreportparser._pattern import _pattern_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fn: Find Start & End Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_start_position(text: str, \n",
    "                        keys: list[str] | None,\n",
    "                        word_boundary: bool = True,\n",
    "                        flags: re.RegexFlag = re.IGNORECASE,\n",
    "                        ) -> tuple[int, int]:\n",
    "    \"\"\"Helper function to find start position of the section\"\"\"\n",
    "    if keys is None:\n",
    "        return 0, 0\n",
    "    # Warn if start pattern appears more than once\n",
    "    for key in keys:\n",
    "        x = re.findall(key, text, flags)\n",
    "        count = len(x)\n",
    "        if count >= 2:\n",
    "            logging.warning(\"Start pattern `%s` appear %d times in text, only the first one will be matched.\", key, count)\n",
    "            \n",
    "    start_match = _pattern_keys(keys, word_boundary, flags).search(text)\n",
    "    if not start_match:\n",
    "        return -1, -1  # Indicate no match found\n",
    "    return start_match.start(), start_match.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Start pattern `history` appear 3 times in text, only the first one will be matched.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt1 = \"\"\"CT History: A patient presented with these symptoms:\n",
    "- Chest Pain\n",
    "- Dyspnea\n",
    "History: Another History\n",
    "\n",
    "technique: \n",
    "\n",
    "Comparison: None\n",
    "\"\"\"\n",
    "\n",
    "_find_start_position(txt1, [\"history\", \"technique\"])\n",
    "# _pattern_keys([\"history\", \"technique\"]).search(txt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "def _find_start_position_all(\n",
    "    text: str,\n",
    "    keys: list[str] | None,\n",
    "    word_boundary: bool = False,\n",
    "    flags: re.RegexFlag = re.IGNORECASE,\n",
    ") -> List[Tuple[int, int]]:\n",
    "    \"\"\"Helper function to find all start positions of the sections.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The input text to search through\n",
    "    keys : list[str] | None\n",
    "        List of possible section start markers\n",
    "    word_boundary : bool, optional\n",
    "        Whether to use word boundaries in pattern matching\n",
    "    flags : re.RegexFlag, optional\n",
    "        Regex flags to use in pattern matching\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List[Tuple[int, int]]\n",
    "        List of tuples containing (start, end) positions of all matches.\n",
    "        Returns [(0, 0)] if keys is None.\n",
    "        Returns [] if no matches found.\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        return [(0, 0)]\n",
    "        \n",
    "    pattern = _pattern_keys(keys, word_boundary, flags)\n",
    "    matches = list(pattern.finditer(text))\n",
    "    if not matches:\n",
    "        return []\n",
    "        \n",
    "    return [(m.start(), m.end()) for m in matches]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 6), (43, 47)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2 = \"\"\"\n",
    "Human: Hello\n",
    "AI: Hi, How can I help you?\n",
    "\n",
    "User: None\n",
    "AI: Bye\n",
    "\"\"\"\n",
    "\n",
    "_find_start_position_all(txt2, [\"Human\", \"User\"])\n",
    "# _pattern_keys([\"history\", \"technique\"]).search(txt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_end_position_greedy(text: str, \n",
    "                            keys: list[str] | None, \n",
    "                            start_pos: int,\n",
    "                            word_boundary: bool = True,\n",
    "                            flags: re.RegexFlag = re.IGNORECASE,\n",
    "                            ) -> int:\n",
    "    \"\"\"Find the end position of a section using greedy matching.\n",
    "    \n",
    "    Searches for any of the end keys and returns the position of the first match found.\n",
    "    This is faster but less precise when order matters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The input text to search through\n",
    "    keys : list[str] | None\n",
    "        List of possible end markers\n",
    "    start_pos : int\n",
    "        Position in text to start searching from\n",
    "    word_boundary : bool, optional\n",
    "        Whether to use word boundaries in pattern matching\n",
    "    flags : re.RegexFlag, optional\n",
    "        Regex flags to use in pattern matching\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The ending position in the text\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        return len(text)\n",
    "    end_match = _pattern_keys(keys, word_boundary, flags).search(text[start_pos:])\n",
    "    return len(text) if not end_match else start_pos + end_match.start()\n",
    "\n",
    "\n",
    "def _find_end_position_sequential(text: str, \n",
    "                                keys: list[str] | None, \n",
    "                                start_pos: int,\n",
    "                                word_boundary: bool = True,\n",
    "                                flags: re.RegexFlag = re.IGNORECASE,\n",
    "                                ) -> int:\n",
    "    \"\"\"Find the end position of a section using sequential matching.\n",
    "    \n",
    "    Tries each end key in order and returns the position of the first successful match.\n",
    "    More precise when the order of keys matters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The input text to search through\n",
    "    keys : list[str] | None\n",
    "        List of possible end markers, tried in order\n",
    "    start_pos : int\n",
    "        Position in text to start searching from\n",
    "    word_boundary : bool, optional\n",
    "        Whether to use word boundaries in pattern matching\n",
    "    flags : re.RegexFlag, optional\n",
    "        Regex flags to use in pattern matching\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The ending position in the text\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        return len(text)\n",
    "        \n",
    "    search_text = text[start_pos:]\n",
    "    \n",
    "    # Try each key in sequence\n",
    "    for key in keys:\n",
    "        # Create pattern for single key\n",
    "        pattern = _pattern_keys([key], word_boundary, flags)\n",
    "        match = pattern.search(search_text)\n",
    "        \n",
    "        if match:\n",
    "            # Return position relative to original text\n",
    "            return start_pos + match.start()\n",
    "            \n",
    "    # If no matches found, return end of text\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt1 = \"\"\"CT of the chest\n",
    "History: A patient presented with these symptoms:\n",
    "- Chest Pain\n",
    "- Dyspnea\n",
    "History: Another\n",
    "\n",
    "technique: CT chest\n",
    "\n",
    "Comparison: None\n",
    "\"\"\"\n",
    "\n",
    "_find_end_position_greedy(txt1, [\"history\", \"technique\"], start_pos=1)\n",
    "_find_end_position_sequential(txt1, [\"technique\", \"history\"], start_pos=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class: Extract Section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Literal\n",
    "\n",
    "class SectionExtractor:\n",
    "    \"\"\"Extract sections from text based on start and end keys.\n",
    "    \n",
    "    This class provides functionality to extract sections of text that begin with\n",
    "    specified start keys and end with specified end keys. It encapsulates the\n",
    "    pattern matching configuration and provides a reusable interface for text extraction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start_keys : list[str] | None\n",
    "        List of possible section start markers. If None, the section will be\n",
    "        extracted from the beginning of the text.\n",
    "    end_keys : list[str] | None\n",
    "        List of possible section end markers. If None, the section will be\n",
    "        extracted until the end of the text.\n",
    "    include_start_keys : bool, optional\n",
    "        Whether to include the start key in the extracted section.\n",
    "        Default is False.\n",
    "    word_boundary : bool, optional\n",
    "        Whether to wrap word boundary `\\b` around the keys.\n",
    "        Default is True.\n",
    "    flags : re.RegexFlag, optional\n",
    "        Regex flags to use in pattern matching.\n",
    "        Default is re.IGNORECASE.\n",
    "    match_strategy : {\"greedy\", \"sequential\"}, optional\n",
    "        Strategy for matching end keys:\n",
    "        - \"greedy\": Use first matching end key (faster)\n",
    "        - \"sequential\": Try end keys in order (more precise)\n",
    "        Default is \"greedy\".\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    ```{python}\n",
    "    # Create an extractor for finding text between headers\n",
    "    extractor = SectionExtractor(\n",
    "        start_keys=[\"FINDINGS:\"],\n",
    "        end_keys=[\"IMPRESSION:\", \"CONCLUSION:\"]\n",
    "    )\n",
    "    \n",
    "    # Extract section from text\n",
    "    text = \"FINDINGS: Normal study. IMPRESSION: No abnormality.\"\n",
    "    section = extractor.extract(text)\n",
    "    print(section)  # Output: \"Normal study.\"\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        start_keys: list[str] | None,\n",
    "        end_keys: list[str] | None,\n",
    "        include_start_keys: bool = False,\n",
    "        word_boundary: bool = False,\n",
    "        flags: re.RegexFlag = re.IGNORECASE,\n",
    "        match_strategy: Literal[\"greedy\", \"sequential\"] = \"greedy\",\n",
    "    ):\n",
    "        self.start_keys = start_keys\n",
    "        self.end_keys = end_keys\n",
    "        self.include_start_keys = include_start_keys\n",
    "        self.word_boundary = word_boundary\n",
    "        self.flags = flags\n",
    "        \n",
    "        # Validate match strategy\n",
    "        match_strategy_options = frozenset({\"greedy\", \"sequential\"})\n",
    "        if match_strategy not in match_strategy_options:\n",
    "            raise ValueError(\n",
    "                f\"Invalid value: {match_strategy}. \"\n",
    "                f\"Must be one of: {', '.join(match_strategy_options)}\"\n",
    "            )\n",
    "        self.match_strategy = match_strategy\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Return a detailed string representation of the SectionExtractor.\n",
    "        \"\"\"\n",
    "        # Format start_keys and end_keys lists\n",
    "        start_keys_str = f\"[{', '.join(repr(k) for k in self.start_keys)}]\" if self.start_keys else \"None\"\n",
    "        end_keys_str = f\"[{', '.join(repr(k) for k in self.end_keys)}]\" if self.end_keys else \"None\"\n",
    "        \n",
    "        # Format flags \n",
    "        flags_name = self.flags.name if hasattr(self.flags, 'name') else str(self.flags)\n",
    "        \n",
    "        return (\n",
    "            f\"{self.__class__.__name__}(\"\n",
    "            f\"start_keys={start_keys_str}, \"\n",
    "            f\"end_keys={end_keys_str}, \"\n",
    "            f\"include_start_keys={self.include_start_keys=}, \"\n",
    "            f\"word_boundary={self.word_boundary}, \"\n",
    "            f\"flags=re.{flags_name}, \"\n",
    "            f\"match_strategy='{self.match_strategy}')\"\n",
    "        )\n",
    "\n",
    "    def extract(self, text: str) -> str:\n",
    "        \"\"\"Extract a section from the text using configured patterns.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            The input text to extract section from.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The extracted section text. Returns empty string if section not found.\n",
    "            \n",
    "        Examples\n",
    "        --------\n",
    "        ```{python}\n",
    "        extractor = SectionExtractor(\n",
    "            start_keys=[\"FINDINGS:\"], \n",
    "            end_keys=[\"IMPRESSION:\"]\n",
    "        )\n",
    "        text = \"FINDINGS: Normal. IMPRESSION: Clear.\"\n",
    "        section = extractor.extract(text)\n",
    "        print(section) \n",
    "        ```\n",
    "        \"\"\"\n",
    "        # Find start position\n",
    "        start_idx_start, start_idx_end = _find_start_position(text, self.start_keys)\n",
    "        if start_idx_start == -1:  # No start match found\n",
    "            return \"\"\n",
    "        \n",
    "        # Find end position based on strategy\n",
    "        if self.match_strategy == \"greedy\":\n",
    "            end_idx = _find_end_position_greedy(text, self.end_keys, start_idx_start)\n",
    "        else:\n",
    "            end_idx = _find_end_position_sequential(text, self.end_keys, start_idx_start)\n",
    "        \n",
    "        # Extract the section\n",
    "        section_start = start_idx_start if self.include_start_keys else start_idx_end\n",
    "        return text[section_start:end_idx].strip()\n",
    "\n",
    "\n",
    "    def extract_all(self, text: str) -> List[str]:\n",
    "            \"\"\"Extract all sections from the text that match the configured patterns.\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            text : str\n",
    "                The input text to extract sections from\n",
    "                \n",
    "            Returns\n",
    "            -------\n",
    "            List[str]\n",
    "                List of extracted section texts. Returns empty list if no sections found.\n",
    "                \n",
    "            Examples\n",
    "            --------\n",
    "            ```{python}\n",
    "            extractor = SectionExtractor(\n",
    "                start_keys=[\"FINDING:\"],\n",
    "                end_keys=[\"IMPRESSION:\"]\n",
    "            )\n",
    "            text = '''\n",
    "            FINDING: First observation\n",
    "            IMPRESSION: OK\n",
    "            FINDING: Second observation\n",
    "            IMPRESSION: Also OK\n",
    "            '''\n",
    "            sections = extractor.extract_all(text)\n",
    "            print(sections)  # ['First observation', 'Second observation']\n",
    "            ```\n",
    "            \"\"\"\n",
    "            # Find all start positions\n",
    "            start_positions = _find_start_position_all(\n",
    "                text,\n",
    "                self.start_keys,\n",
    "                self.word_boundary,\n",
    "                self.flags\n",
    "            )\n",
    "            \n",
    "            if not start_positions:\n",
    "                return []\n",
    "                \n",
    "            sections = []\n",
    "            \n",
    "            # Process each start position\n",
    "            for start_idx_start, start_idx_end in start_positions:\n",
    "                # Find end position based on strategy\n",
    "                if self.match_strategy == \"greedy\":\n",
    "                    end_idx = _find_end_position_greedy(\n",
    "                        text,\n",
    "                        self.end_keys,\n",
    "                        start_idx_start,\n",
    "                        self.word_boundary,\n",
    "                        self.flags\n",
    "                    )\n",
    "                else:\n",
    "                    end_idx = _find_end_position_sequential(\n",
    "                        text,\n",
    "                        self.end_keys,\n",
    "                        start_idx_start,\n",
    "                        self.word_boundary,\n",
    "                        self.flags\n",
    "                    )\n",
    "                \n",
    "                # Extract the section\n",
    "                section_start = start_idx_start if self.include_start_keys else start_idx_end\n",
    "                section = text[section_start:end_idx].strip()\n",
    "                \n",
    "                if section:  # Only add non-empty sections\n",
    "                    sections.append(section)\n",
    "\n",
    "            return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Start pattern `history` appear 2 times in text, only the first one will be matched.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "': A patient presented with these symptoms:\\n- Chest Pain\\n- Dyspnea\\nHistory: Another\\n\\ntechnique: CT chest'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hx_extractor_1 = SectionExtractor([\"history\", \"technique\"], [\"comparison\"], word_boundary = False)\n",
    "hx_extractor_1.extract(txt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[': Hello', ': None']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2 = \"\"\"\n",
    "Human: Hello\n",
    "AI: Hi, How can I help you?\n",
    "\n",
    "User: None\n",
    "AI: Bye\n",
    "\"\"\"\n",
    "\n",
    "SectionExtractor([\"Human\", \"User\"], [\"AI\"], word_boundary = False).extract_all(txt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main: `extract_section()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def extract_section(text: str,\n",
    "                   start_keys: list[str] | None,\n",
    "                   end_keys: list[str] | None,\n",
    "                   include_start_keys: bool = False,\n",
    "                   word_boundary: bool = True,\n",
    "                   flags: re.RegexFlag = re.IGNORECASE,\n",
    "                   match_strategy: Literal[\"greedy\", \"sequential\"] = \"greedy\",\n",
    "                   ) -> str | Literal[\"\"]:\n",
    "    \"\"\"Extract a section of text between specified start and end keys.\n",
    "    \n",
    "    [previous docstring content]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    [previous parameters]\n",
    "    match_strategy : MatchStrategy, optional\n",
    "        Strategy for matching end keys:\n",
    "        - \"greedy\": Use first matching end key (faster)\n",
    "        - \"sequential\": Try end keys in order (more precise)\n",
    "        Default is GREEDY\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> text = \"FINDINGS: Normal. TECHNIQUE: MRI. IMPRESSION: Clear.\"\n",
    "    >>> # Using sequential matching\n",
    "    >>> extract_section(text, [\"FINDINGS:\"], \n",
    "    ...                [\"TECHNIQUE:\", \"IMPRESSION:\"],\n",
    "    ...                match_strategy=\"sequential\")\n",
    "    'Normal.'\n",
    "    \"\"\"\n",
    "    # Find start position\n",
    "    start_idx_start, start_idx_end = _find_start_position(text, start_keys)\n",
    "    if start_idx_start == -1:  # No start match found\n",
    "        return \"\"\n",
    "    \n",
    "    # Find end position based on strategy\n",
    "    match_strategy_options =  frozenset({\"greedy\", \"sequential\"})\n",
    "    if match_strategy not in match_strategy_options:\n",
    "        raise ValueError(f\"Invalid value: {match_strategy}. Must be one of: {', '.join(match_strategy_options)}\")\n",
    "    \n",
    "    if match_strategy == \"greedy\":\n",
    "        end_idx = _find_end_position_greedy(text, end_keys, start_idx_start)\n",
    "    else:\n",
    "        end_idx = _find_end_position_sequential(text, end_keys, start_idx_start)\n",
    "    \n",
    "    # Extract the section\n",
    "    section_start = start_idx_start if include_start_keys else start_idx_end\n",
    "    return text[section_start:end_idx].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Start pattern `history` appear 2 times in text, only the first one will be matched.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "': A patient presented with these symptoms:\\n- Chest Pain\\n- Dyspnea\\nHistory: Another\\n\\ntechnique: CT chest'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_section(txt1, [\"history\", \"technique\"], [\"comparison\"])\n",
    "# extract_section(txt1, None, [\"History\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Start pattern `history\\W*` appear 2 times in text, only the first one will be matched.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A patient presented with these symptoms:\\n- Chest Pain\\n- Dyspnea\\nHistory: Another\\n\\ntechnique: CT chest'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_section(txt1, \n",
    "                start_keys=[r\"history\\W*\"], \n",
    "                end_keys=[r\"Comparison\\W*\"], \n",
    "                word_boundary= False,\n",
    "                include_start_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A patient presented with these symptoms:\\n- Chest Pain\\n- Dyspnea'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rep_md1 = \"\"\"\n",
    "History: A patient presented with these symptoms:\n",
    "- Chest Pain\n",
    "- Dyspnea\n",
    "\n",
    "**technique:** CT chest\n",
    "\"\"\"\n",
    "\n",
    "extract_section(t_rep_md1, \n",
    "                start_keys=[r\"\\W*History\\W*\"], \n",
    "                end_keys=[r\"\\W*technique\\W*\"],\n",
    "                word_boundary= True,\n",
    "                include_start_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A\\n- B\\n- C'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rep_md2 = \"\"\"\n",
    "Finding: \n",
    "- A\n",
    "- B\n",
    "- C\n",
    "\n",
    "**Impression:**\n",
    "- D\n",
    "- E\n",
    "- F\n",
    "\"\"\"\n",
    "\n",
    "extract_section(t_rep_md2, \n",
    "                start_keys=[r\"\\W*Finding(s?)\\W*\"], \n",
    "                end_keys=[r\"\\W*Impression\\W*\"],\n",
    "                word_boundary= True,\n",
    "                include_start_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A\\n- B\\n- C'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rep_md3 = \"\"\"\n",
    "Clinical Indications: \n",
    "- A\n",
    "- B\n",
    "- C\n",
    "\n",
    "**Impression:**\n",
    "- D\n",
    "- E\n",
    "- F\n",
    "\"\"\"\n",
    "\n",
    "extract_section(t_rep_md3, \n",
    "                start_keys= [r\"\\W*history\\W*\", r\"\\W*indication(s?)\\W*\", *[rf\"\\W*clinical\\s+{h}\\W*\" for h in [\"history\", r\"indication(s?)\"]]],\n",
    "                end_keys=[r\"\\W*Impression\\W*\"],\n",
    "                word_boundary= True,\n",
    "                include_start_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CT CHEST WITH CONTRAST\\nCT WHOLE ABODMEN'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Title\n",
    "t_rep_md4 = \"\"\"\n",
    "CT CHEST WITH CONTRAST\n",
    "CT WHOLE ABODMEN\n",
    "\n",
    "History: blah blah blah\n",
    "\n",
    "Comparison: None\n",
    "\n",
    "Impression: blah blah blah\n",
    "\"\"\"\n",
    "\n",
    "extract_section(t_rep_md4, \n",
    "                start_keys= None,\n",
    "                end_keys=[r\"\\W*History\\W*\"],\n",
    "                word_boundary= True,\n",
    "                include_start_keys=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CT CHEST WITH CONTRAST\\nCT WHOLE ABODMEN\\n\\nBlah'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Title\n",
    "t_rep_md4 = \"\"\"\n",
    "CT CHEST WITH CONTRAST\n",
    "CT WHOLE ABODMEN\n",
    "\n",
    "Blah\n",
    "\"\"\"\n",
    "\n",
    "extract_section(t_rep_md4, \n",
    "                start_keys= None,\n",
    "                end_keys=[r\"\\W*Impression\\W*\"],\n",
    "                word_boundary= True,\n",
    "                include_start_keys=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def extract_section2(text: str,\n",
    "                   start_keys: list[str] | None,\n",
    "                   end_keys: list[str] | None,\n",
    "                   include_start_keys: bool = False,\n",
    "                   word_boundary: bool = True,\n",
    "                   flags: re.RegexFlag = re.IGNORECASE,\n",
    "                   ) -> str | Literal[\"\"]:\n",
    "\n",
    "    # Find start position\n",
    "    start_idx_start, start_idx_end = _find_start_position(text, start_keys)\n",
    "    if start_idx_start == -1:  # No start match found\n",
    "        return \"\"\n",
    "    \n",
    "    # Find end position\n",
    "    end_idx = _find_end_position(text, end_keys, start_idx_start)\n",
    "    \n",
    "    # Extract the section\n",
    "    section_start = start_idx_start if include_start_keys else start_idx_end\n",
    "    return text[section_start:end_idx].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MINIMAL_REPORT_MD = \"\"\"**EMERGENCY CT BRAIN**\n",
    "\n",
    "**HISTORY:** 25F, dizziness and LOC\n",
    "\n",
    "**TECHNIQUE:** CT brain without contrast\n",
    "\n",
    "**FINDINGS:** Normal study\n",
    "- No hemorrhage\n",
    "- No mass\n",
    "\n",
    "**IMPRESSION:** No acute abnormality\"\"\"\n",
    "\n",
    "def test_extract_section_markdown(report_md):\n",
    "    \"\"\"Test section extraction from markdown formatted text\"\"\"\n",
    "    # Extract HISTORY section\n",
    "    history = extract_section(\n",
    "        report_md,\n",
    "        start_keys=[\"**HISTORY:**\"],\n",
    "        end_keys=[\"**TECHNIQUE:**\"],\n",
    "        include_start_keys=True,\n",
    "        word_boundary=False)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_section(\n",
    "        MINIMAL_REPORT_MD,\n",
    "        start_keys=[r\"ssss\"],\n",
    "        end_keys=[r\"svvv\"],\n",
    "        include_start_keys=True,\n",
    "        word_boundary=False,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
