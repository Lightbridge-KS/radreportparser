{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev: Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent)) \n",
    "\n",
    "\n",
    "from radreportparser._pattern import _pattern_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fn: Find Start & End Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_start_position(text: str, \n",
    "                        keys: list[str] | None,\n",
    "                        word_boundary: bool = True,\n",
    "                        flags: re.RegexFlag = re.IGNORECASE,\n",
    "                        ) -> tuple[int, int]:\n",
    "    \"\"\"Helper function to find start position of the section\"\"\"\n",
    "    if keys is None:\n",
    "        return 0, 0\n",
    "    # Warn if start pattern appears more than once\n",
    "    for key in keys:\n",
    "        x = re.findall(key, text, flags)\n",
    "        count = len(x)\n",
    "        if count >= 2:\n",
    "            logging.warning(\"Start pattern `%s` appear %d times in text, only the first one will be matched.\", key, count)\n",
    "            \n",
    "    start_match = _pattern_keys(keys, word_boundary, flags).search(text)\n",
    "    if not start_match:\n",
    "        return -1, -1  # Indicate no match found\n",
    "    return start_match.start(), start_match.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Start pattern `history` appear 3 times in text, only the first one will be matched.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt1 = \"\"\"CT History: A patient presented with these symptoms:\n",
    "- Chest Pain\n",
    "- Dyspnea\n",
    "History: Another History\n",
    "\n",
    "technique: \n",
    "\n",
    "Comparison: None\n",
    "\"\"\"\n",
    "\n",
    "_find_start_position(txt1, [\"history\", \"technique\"])\n",
    "# _pattern_keys([\"history\", \"technique\"]).search(txt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_end_position_greedy(text: str, \n",
    "                            keys: list[str] | None, \n",
    "                            start_pos: int,\n",
    "                            word_boundary: bool = True,\n",
    "                            flags: re.RegexFlag = re.IGNORECASE,\n",
    "                            ) -> int:\n",
    "    \"\"\"Find the end position of a section using greedy matching.\n",
    "    \n",
    "    Searches for any of the end keys and returns the position of the first match found.\n",
    "    This is faster but less precise when order matters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The input text to search through\n",
    "    keys : list[str] | None\n",
    "        List of possible end markers\n",
    "    start_pos : int\n",
    "        Position in text to start searching from\n",
    "    word_boundary : bool, optional\n",
    "        Whether to use word boundaries in pattern matching\n",
    "    flags : re.RegexFlag, optional\n",
    "        Regex flags to use in pattern matching\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The ending position in the text\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        return len(text)\n",
    "    end_match = _pattern_keys(keys, word_boundary, flags).search(text[start_pos:])\n",
    "    return len(text) if not end_match else start_pos + end_match.start()\n",
    "\n",
    "\n",
    "def _find_end_position_sequential(text: str, \n",
    "                                keys: list[str] | None, \n",
    "                                start_pos: int,\n",
    "                                word_boundary: bool = True,\n",
    "                                flags: re.RegexFlag = re.IGNORECASE,\n",
    "                                ) -> int:\n",
    "    \"\"\"Find the end position of a section using sequential matching.\n",
    "    \n",
    "    Tries each end key in order and returns the position of the first successful match.\n",
    "    More precise when the order of keys matters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The input text to search through\n",
    "    keys : list[str] | None\n",
    "        List of possible end markers, tried in order\n",
    "    start_pos : int\n",
    "        Position in text to start searching from\n",
    "    word_boundary : bool, optional\n",
    "        Whether to use word boundaries in pattern matching\n",
    "    flags : re.RegexFlag, optional\n",
    "        Regex flags to use in pattern matching\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The ending position in the text\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        return len(text)\n",
    "        \n",
    "    search_text = text[start_pos:]\n",
    "    \n",
    "    # Try each key in sequence\n",
    "    for key in keys:\n",
    "        # Create pattern for single key\n",
    "        pattern = _pattern_keys([key], word_boundary, flags)\n",
    "        match = pattern.search(search_text)\n",
    "        \n",
    "        if match:\n",
    "            # Return position relative to original text\n",
    "            return start_pos + match.start()\n",
    "            \n",
    "    # If no matches found, return end of text\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt1 = \"\"\"CT of the chest\n",
    "History: A patient presented with these symptoms:\n",
    "- Chest Pain\n",
    "- Dyspnea\n",
    "History: Another\n",
    "\n",
    "technique: CT chest\n",
    "\n",
    "Comparison: None\n",
    "\"\"\"\n",
    "\n",
    "_find_end_position_greedy(txt1, [\"history\", \"technique\"], start_pos=1)\n",
    "_find_end_position_sequential(txt1, [\"technique\", \"history\"], start_pos=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main: `extract_section()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def extract_section(text: str,\n",
    "                   start_keys: list[str] | None,\n",
    "                   end_keys: list[str] | None,\n",
    "                   include_start_keys: bool = False,\n",
    "                   word_boundary: bool = True,\n",
    "                   flags: re.RegexFlag = re.IGNORECASE,\n",
    "                   match_strategy: Literal[\"greedy\", \"sequential\"] = \"greedy\",\n",
    "                   ) -> str | Literal[\"\"]:\n",
    "    \"\"\"Extract a section of text between specified start and end keys.\n",
    "    \n",
    "    [previous docstring content]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    [previous parameters]\n",
    "    match_strategy : MatchStrategy, optional\n",
    "        Strategy for matching end keys:\n",
    "        - \"greedy\": Use first matching end key (faster)\n",
    "        - \"sequential\": Try end keys in order (more precise)\n",
    "        Default is GREEDY\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> text = \"FINDINGS: Normal. TECHNIQUE: MRI. IMPRESSION: Clear.\"\n",
    "    >>> # Using sequential matching\n",
    "    >>> extract_section(text, [\"FINDINGS:\"], \n",
    "    ...                [\"TECHNIQUE:\", \"IMPRESSION:\"],\n",
    "    ...                match_strategy=\"sequential\")\n",
    "    'Normal.'\n",
    "    \"\"\"\n",
    "    # Find start position\n",
    "    start_idx_start, start_idx_end = _find_start_position(text, start_keys)\n",
    "    if start_idx_start == -1:  # No start match found\n",
    "        return \"\"\n",
    "    \n",
    "    # Find end position based on strategy\n",
    "    match_strategy_options =  frozenset({\"greedy\", \"sequential\"})\n",
    "    if match_strategy not in match_strategy_options:\n",
    "        raise ValueError(f\"Invalid value: {match_strategy}. Must be one of: {', '.join(match_strategy_options)}\")\n",
    "    \n",
    "    if match_strategy == \"greedy\":\n",
    "        end_idx = _find_end_position_greedy(text, end_keys, start_idx_start)\n",
    "    else:\n",
    "        end_idx = _find_end_position_sequential(text, end_keys, start_idx_start)\n",
    "    \n",
    "    # Extract the section\n",
    "    section_start = start_idx_start if include_start_keys else start_idx_end\n",
    "    return text[section_start:end_idx].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Start pattern `history` appear 2 times in text, only the first one will be matched.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "': A patient presented with these symptoms:\\n- Chest Pain\\n- Dyspnea\\nHistory: Another\\n\\ntechnique: CT chest'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_section(txt1, [\"history\", \"technique\"], [\"comparison\"])\n",
    "# extract_section(txt1, None, [\"History\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Start pattern `history\\W*` appear 2 times in text, only the first one will be matched.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A patient presented with these symptoms:\\n- Chest Pain\\n- Dyspnea\\nHistory: Another\\n\\ntechnique: CT chest'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_section(txt1, \n",
    "                start_keys=[r\"history\\W*\"], \n",
    "                end_keys=[r\"Comparison\\W*\"], \n",
    "                word_boundary= False,\n",
    "                include_start_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A patient presented with these symptoms:\\n- Chest Pain\\n- Dyspnea'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rep_md1 = \"\"\"\n",
    "History: A patient presented with these symptoms:\n",
    "- Chest Pain\n",
    "- Dyspnea\n",
    "\n",
    "**technique:** CT chest\n",
    "\"\"\"\n",
    "\n",
    "extract_section(t_rep_md1, \n",
    "                start_keys=[r\"\\W*History\\W*\"], \n",
    "                end_keys=[r\"\\W*technique\\W*\"],\n",
    "                word_boundary= True,\n",
    "                include_start_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A\\n- B\\n- C'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_rep_md2 = \"\"\"\n",
    "Finding: \n",
    "- A\n",
    "- B\n",
    "- C\n",
    "\n",
    "**Impression:**\n",
    "- D\n",
    "- E\n",
    "- F\n",
    "\"\"\"\n",
    "\n",
    "extract_section(t_rep_md2, \n",
    "                start_keys=[r\"\\W*Finding(s?)\\W*\"], \n",
    "                end_keys=[r\"\\W*Impression\\W*\"],\n",
    "                word_boundary= True,\n",
    "                include_start_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A\\n- B\\n- C'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_rep_md3 = \"\"\"\n",
    "Clinical Indications: \n",
    "- A\n",
    "- B\n",
    "- C\n",
    "\n",
    "**Impression:**\n",
    "- D\n",
    "- E\n",
    "- F\n",
    "\"\"\"\n",
    "\n",
    "extract_section(t_rep_md3, \n",
    "                start_keys= [r\"\\W*history\\W*\", r\"\\W*indication(s?)\\W*\", *[rf\"\\W*clinical\\s+{h}\\W*\" for h in [\"history\", r\"indication(s?)\"]]],\n",
    "                end_keys=[r\"\\W*Impression\\W*\"],\n",
    "                word_boundary= True,\n",
    "                include_start_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CT CHEST WITH CONTRAST\\nCT WHOLE ABODMEN'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Title\n",
    "t_rep_md4 = \"\"\"\n",
    "CT CHEST WITH CONTRAST\n",
    "CT WHOLE ABODMEN\n",
    "\n",
    "History: blah blah blah\n",
    "\n",
    "Comparison: None\n",
    "\n",
    "Impression: blah blah blah\n",
    "\"\"\"\n",
    "\n",
    "extract_section(t_rep_md4, \n",
    "                start_keys= None,\n",
    "                end_keys=[r\"\\W*History\\W*\"],\n",
    "                word_boundary= True,\n",
    "                include_start_keys=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CT CHEST WITH CONTRAST\\nCT WHOLE ABODMEN\\n\\nBlah'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Title\n",
    "t_rep_md4 = \"\"\"\n",
    "CT CHEST WITH CONTRAST\n",
    "CT WHOLE ABODMEN\n",
    "\n",
    "Blah\n",
    "\"\"\"\n",
    "\n",
    "extract_section(t_rep_md4, \n",
    "                start_keys= None,\n",
    "                end_keys=[r\"\\W*Impression\\W*\"],\n",
    "                word_boundary= True,\n",
    "                include_start_keys=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def extract_section2(text: str,\n",
    "                   start_keys: list[str] | None,\n",
    "                   end_keys: list[str] | None,\n",
    "                   include_start_keys: bool = False,\n",
    "                   word_boundary: bool = True,\n",
    "                   flags: re.RegexFlag = re.IGNORECASE,\n",
    "                   ) -> str | Literal[\"\"]:\n",
    "\n",
    "    # Find start position\n",
    "    start_idx_start, start_idx_end = _find_start_position(text, start_keys)\n",
    "    if start_idx_start == -1:  # No start match found\n",
    "        return \"\"\n",
    "    \n",
    "    # Find end position\n",
    "    end_idx = _find_end_position(text, end_keys, start_idx_start)\n",
    "    \n",
    "    # Extract the section\n",
    "    section_start = start_idx_start if include_start_keys else start_idx_end\n",
    "    return text[section_start:end_idx].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "nothing to repeat at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 24\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Extract HISTORY section\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     history \u001b[38;5;241m=\u001b[39m extract_section(\n\u001b[1;32m     17\u001b[0m         report_md,\n\u001b[1;32m     18\u001b[0m         start_keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**HISTORY:**\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     19\u001b[0m         end_keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**TECHNIQUE:**\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     20\u001b[0m         include_start_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m         word_boundary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mtest_extract_section_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMINIMAL_REPORT_MD\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[99], line 16\u001b[0m, in \u001b[0;36mtest_extract_section_markdown\u001b[0;34m(report_md)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test section extraction from markdown formatted text\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Extract HISTORY section\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mextract_section\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreport_md\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m**HISTORY:**\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m**TECHNIQUE:**\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_start_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mword_boundary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[65], line 34\u001b[0m, in \u001b[0;36mextract_section\u001b[0;34m(text, start_keys, end_keys, include_start_keys, word_boundary, flags, match_strategy)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extract a section of text between specified start and end keys.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m[previous docstring content]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m'Normal.'\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Find start position\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m start_idx_start, start_idx_end \u001b[38;5;241m=\u001b[39m \u001b[43m_find_start_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_idx_start \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# No start match found\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[78], line 11\u001b[0m, in \u001b[0;36m_find_start_position\u001b[0;34m(text, keys, word_boundary, flags)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Warn if start pattern appears more than once\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys:\n\u001b[0;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm-env/lib/python3.12/re/__init__.py:217\u001b[0m, in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindall\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m \n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfindall(string)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm-env/lib/python3.12/re/__init__.py:307\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    306\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m--> 307\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m&\u001b[39m DEBUG:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm-env/lib/python3.12/re/_compiler.py:745\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[1;32m    744\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m--> 745\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm-env/lib/python3.12/re/_parser.py:979\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    976\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[1;32m    977\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m--> 979\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSRE_FLAG_VERBOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm-env/lib/python3.12/re/_parser.py:460\u001b[0m, in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    458\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m     itemsappend(\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm-env/lib/python3.12/re/_parser.py:687\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    685\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m item \u001b[38;5;129;01mor\u001b[39;00m item[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m AT:\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnothing to repeat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    688\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m here \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(this))\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _REPEATCODES:\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiple repeat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    691\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m here \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(this))\n",
      "\u001b[0;31merror\u001b[0m: nothing to repeat at position 0"
     ]
    }
   ],
   "source": [
    "\n",
    "MINIMAL_REPORT_MD = \"\"\"**EMERGENCY CT BRAIN**\n",
    "\n",
    "**HISTORY:** 25F, dizziness and LOC\n",
    "\n",
    "**TECHNIQUE:** CT brain without contrast\n",
    "\n",
    "**FINDINGS:** Normal study\n",
    "- No hemorrhage\n",
    "- No mass\n",
    "\n",
    "**IMPRESSION:** No acute abnormality\"\"\"\n",
    "\n",
    "def test_extract_section_markdown(report_md):\n",
    "    \"\"\"Test section extraction from markdown formatted text\"\"\"\n",
    "    # Extract HISTORY section\n",
    "    history = extract_section(\n",
    "        report_md,\n",
    "        start_keys=[\"**HISTORY:**\"],\n",
    "        end_keys=[\"**TECHNIQUE:**\"],\n",
    "        include_start_keys=True,\n",
    "        word_boundary=False)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_section(\n",
    "        MINIMAL_REPORT_MD,\n",
    "        start_keys=[r\"ssss\"],\n",
    "        end_keys=[r\"svvv\"],\n",
    "        include_start_keys=True,\n",
    "        word_boundary=False,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
